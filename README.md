# ğŸ“° Fake News Detection using Deep Learning (Flask)

This project predicts whether a news article is **Fake** or **Real** using a trained Deep Learning model.
It uses **NLP preprocessing**, **tokenization**, and **sequence padding (MAX_LEN = 400)** with the **same cleaning logic used during training** to ensure accurate predictions.

This README is written in a **simple, learning-friendly way** so you can clearly understand how the project works.

---

# ğŸ“Œ Project Objective

The goal of this project is to:

âœ” Take news text as input
âœ” Clean and preprocess the text
âœ” Convert text into numeric format
âœ” Pass it to a Deep Learning model
âœ” Predict whether the news is **Fake** or **Real**

---

# ğŸ§  Technologies Used

* Python
* TensorFlow / Keras
* Flask (Web Framework)
* NLP (Natural Language Processing)
* NLTK (Stopwords removal)

---

# âš™ï¸ Model Information

We use Deep Learning architectures such as:

* LSTM
* BiLSTM
* CNN (optional improvement)

The text is converted using:

* Keras Tokenizer
* Padding length = **400**

---

# ğŸ“ Project Structure

```
FakeNewsProject/
â”‚â”€â”€ app.py                 # Main Flask application
â”‚â”€â”€ model.h5               # Trained deep learning model
â”‚â”€â”€ tokenizer.pkl          # Saved tokenizer
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ README.md              # Documentation
â”‚
â”œâ”€â”€ templates/
â”‚   â”‚â”€â”€ index.html         # Input page
â”‚   â”‚â”€â”€ result.html        # Output page
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ preprocessing.py   # Text cleaning & padding functions
â”‚
â””â”€â”€ static/
    â””â”€â”€ style.css          # Optional CSS
```

---

# ğŸ§¹ Text Cleaning Used (Same as Training)

We apply the same preprocessing during training and prediction to avoid errors.

Steps:

1. Convert to lowercase
2. Remove URLs
3. Remove special characters and numbers
4. Remove extra spaces
5. Remove stopwords

Example code:

```python
import re
from nltk.corpus import stopwords

def clean_text(text):
    text = text.lower()
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"[^a-zA-Z ]", " ", text)
    text = re.sub(r"\s+", " ", text)

    words = text.split()
    words = [w for w in words if w not in stopwords.words('english')]

    return " ".join(words)
```

---

# ğŸ“ Padding Configuration

We use the same padding length used during training:

```
MAX_LEN = 400
```

Example:

```python
from tensorflow.keras.preprocessing.sequence import pad_sequences

sequence = tokenizer.texts_to_sequences([text])
padded = pad_sequences(sequence, maxlen=400)
```

---

# ğŸš€ How to Run the Project

## Step 1 â€” Install Dependencies

```bash
pip install -r requirements.txt
```

---

## Step 2 â€” Download NLTK Stopwords (Important)

Because we use stopwords, run this once:

```bash
python -c "import nltk; nltk.download('stopwords')"
```

---

## Step 3 â€” Run Application

```bash
python app.py
```
# ğŸ–¥ï¸ How the System Works (Flow)

User Input â†’ Cleaning â†’ Tokenization â†’ Padding â†’ Model â†’ Prediction â†’ Result

---

# ğŸ“Š Output

The system will show:

* Fake News âŒ
* Real News âœ…

(Optional: Probability score)

---

# ğŸ§ª Example Fake News

```
Scientists confirm that drinking hot water every 10 minutes kills all cancer cells instantly, according to a secret WHO report.
```

---

# â— Common Errors

## Error: No module named nltk

Solution:

```bash
pip install nltk
python -c "import nltk; nltk.download('stopwords')"
```

---

## Error: Model Not Found

Make sure these files exist:

```
model.h5
tokenizer.pkl
```

---

# ğŸ“Œ Future Improvements

* Attention BiLSTM
* Confidence visualization
* Deploy to cloud (AWS / Render)
* API integration

---

# ğŸ‘¨â€ğŸ’» Learning Outcome

From this project you will learn:

âœ” NLP preprocessing
âœ” Deep Learning for text classification
âœ” Model deployment using Flask
âœ” Real-world ML workflow

---
If you want, I can also provide:

âœ… Training Notebook
âœ… Best Model Architecture (High Accuracy)
âœ… Deployment Guide


